predictions = torch.unsqueeze(torch.from_numpy(model(input_tensor)[output_blob]), 0)
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from your_model_library import Seq2SeqWithAttentionAndTimePrediction  # Replace with your actual model import

def predict_sequence_with_time(model, df, window_size, continuous_features, scaler, weights_path, prediction_horizon):
    """
    Predict the next `prediction_horizon` time steps and their corresponding timestamps using the trained Seq2Seq model.
    """
    # Reinitialize and compile the model
    model = Seq2SeqWithAttentionAndTimePrediction(
        input_dim=df[continuous_features].shape[1] + 1,  # Number of features + 1 for time
        output_dim=3 + 1,  # 3 features (LAT, LON, SOG) + 1 for predicted time
        latent_dim=128,
        num_layers=2,
        timesteps_input=window_size,
        timesteps_output=prediction_horizon
    )

    model.compile(optimizer='adam', loss='mse', metrics=['mae'])
    model.load_weights(weights_path)  # Load the pre-trained weights

    # Preprocess the input data
    X_seq = preprocess_input_data_with_time(df, window_size, continuous_features, scaler)

    # Make predictions
    predictions = model.predict([X_seq, X_seq])
    predicted_values = predictions[0][0, :prediction_horizon, :]  # Get first batch, prediction horizon

    # Extract time deltas and features
    time_deltas = predicted_values[:, -1]  # Last column is time delta
    predicted_features = predicted_values[:, :-1]  # Exclude the last column

    # Ensure time deltas are cumulative
    time_deltas_cumulative = time_deltas.cumsum()

    # Calculate predicted timestamps
    last_timestamp = pd.to_datetime(df['BaseDateTime'].iloc[-1])
    predicted_timestamps = pd.to_timedelta(time_deltas_cumulative, unit='s') + last_timestamp

    # Convert predictions to DataFrame
    predicted_df = pd.DataFrame(predicted_features, columns=continuous_features)
    predicted_df['BaseDateTime'] = predicted_timestamps

    # Prepare observed data
    observed_df = df.iloc[-window_size:].copy()
    observed_df[continuous_features] = scaler.transform(observed_df[continuous_features])
    observed_df['BaseDateTime'] = pd.to_datetime(observed_df['BaseDateTime'])

    return observed_df, predicted_df


# Example usage
if __name__ == "__main__":
    # Parameters
    window_size = 10
    prediction_horizon = 5
    continuous_features = ['LAT', 'LON', 'SOG']
    weights_path = '/content/seq2seq_with_attention.weights.h5'

    # Sample AIS data
    data = {
        'BaseDateTime': pd.date_range(start="2023-01-01", periods=100, freq="S"),
        'LAT': np.random.uniform(35.0, 36.0, 100),
        'LON': np.random.uniform(-120.0, -119.0, 100),
        'SOG': np.random.uniform(5.0, 15.0, 100)
    }
    ais_data = pd.DataFrame(data)

    # Scaling the data
    scaler = StandardScaler()
    scaler.fit(ais_data[continuous_features])

    # Prediction
    observed_df, predicted_df = predict_sequence_with_time(
        model=None,
        df=ais_data,
        window_size=window_size,
        continuous_features=continuous_features,
        scaler=scaler,
        weights_path=weights_path,
        prediction_horizon=prediction_horizon
    )

    # Normalize observed and predicted DataFrames
    observed_normalized = observed_df.copy()
    observed_normalized[continuous_features] = scaler.transform(observed_df[continuous_features])

    predicted_normalized = predicted_df.copy()
    predicted_normalized[continuous_features] = scaler.transform(predicted_df[continuous_features])

    # Print normalized data
    print("Normalized Observed Data:")
    print(observed_normalized)

    print("\nNormalized Predicted Data:")
    print(predicted_normalized)

